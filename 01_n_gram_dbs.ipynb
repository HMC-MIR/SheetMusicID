{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases for each n-gram combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 26 different n-gram combinations with various stride lengths. This notebook constructs a database for each type of n-gram and also a database storing the counts for each n-gram type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import dill\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 4],\n",
       " [0, 5],\n",
       " [0, 6],\n",
       " [0, 1, 2],\n",
       " [0, 1, 3],\n",
       " [0, 1, 4],\n",
       " [0, 1, 5],\n",
       " [0, 1, 6],\n",
       " [0, 2, 3],\n",
       " [0, 2, 4],\n",
       " [0, 2, 5],\n",
       " [0, 2, 6],\n",
       " [0, 3, 4],\n",
       " [0, 3, 5],\n",
       " [0, 3, 6],\n",
       " [0, 4, 5],\n",
       " [0, 4, 6],\n",
       " [0, 5, 6]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = []\n",
    "for n_gram in range(2, 4):\n",
    "    combinations += [[0] + list(tup) for tup in itertools.combinations(range(1, 7), n_gram-1)]\n",
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [\"\".join(str(num) for num in combination) for combination in combinations if combination[-1] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalBscore(bscore_file):\n",
    "    bscore_array = []\n",
    "    with open(bscore_file,'rb') as f:\n",
    "        bscore_array = pickle.load(f)\n",
    "    total_bscore = np.array([]).reshape(62,0)\n",
    "    for page in bscore_array:\n",
    "        try:\n",
    "            total_page = unpackbits(np.array(page), 62)\n",
    "        except TypeError:\n",
    "            total_page = np.array([]).reshape(62,0)\n",
    "            for num in page:\n",
    "                col = np.array(decodeColumn(num)).reshape(62,-1)\n",
    "                total_page = np.concatenate((total_page,col),axis=1)\n",
    "        total_bscore = np.concatenate((total_bscore,total_page),axis=1)\n",
    "    return total_bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeColumn(num):\n",
    "    col = []\n",
    "    for i in range(62):\n",
    "        col.insert(0,num%2)\n",
    "        num = int(num/2)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackbits(x, num_bits):\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "    return np.flip((x & mask).astype(bool).astype(float), 1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We precompute powers of 2 from $2^0$ to $2^{61}$ to speed up calculating hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = 1 << np.arange(62)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fps(data, combinations, dbs, piece):\n",
    "    for colindex in range(len(data)):\n",
    "        for combination in combinations:\n",
    "            cols = []\n",
    "            # we need at least enough fingerprints for all the indices in our combination\n",
    "            try:\n",
    "                for i in combination:\n",
    "                    cols.append(data[colindex+int(i)])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            fp = []\n",
    "            equals_Zero = True\n",
    "            for column in cols:\n",
    "                hashint = int(column.dot(powers))\n",
    "                fp.append(hashint)\n",
    "                if hashint != 0:\n",
    "                    equals_Zero = False\n",
    "            if equals_Zero == True:\n",
    "                continue\n",
    "            dbs[combination][tuple(fp)][piece].append(colindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DB(filelist, combinations, dbs = None):\n",
    "    if not dbs:\n",
    "        dbs = {combination: defaultdict(lambda : defaultdict(list)) for combination in combinations}\n",
    "    with open(filelist, 'r') as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            try:\n",
    "                num = curfile.split('/')[-1][0]\n",
    "                if num == 'd':\n",
    "                    data = getTotalBscore(curfile)\n",
    "                else:\n",
    "                    with open(curfile, 'rb') as pickle_file:\n",
    "                        data = pickle.load(pickle_file)\n",
    "                make_fps(data.T, combinations, dbs, i)\n",
    "            except:\n",
    "                failed.append(curfile)\n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        dill.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = 'cfg_files/db.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/data1/kji/databases_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(db_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a mapping from a number to each piece to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_piece = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filelist, 'r') as f:\n",
    "    failed = []\n",
    "    for i, curfile in enumerate(f):\n",
    "        curfile = curfile.strip().strip('\\n')\n",
    "        piece = curfile.split('/')[-1][:-4]\n",
    "        num_to_piece[i] = piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", \"wb\") as f:\n",
    "    pickle.dump(num_to_piece, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", 'rb') as f:\n",
    "    num_to_piece = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First loop over all combinations (total 26).\n",
    "Then loop over every single file in IMSLP.\n",
    "Then within each file, loop over every single offset and compute the n-gram given the combination.\n",
    "Increment the count for that n-gram combination in the dictionary.\n",
    "When done, pickle the dictionary and free the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(combinations), 3):\n",
    "    dbs = make_DB(filelist, combinations[i: i+3])\n",
    "    for combination in dbs:\n",
    "        store_DB(dbs[combination], combination, db_dir)\n",
    "    dbs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = make_DB(filelist, ['06'])\n",
    "for combination in dbs:\n",
    "    store_DB(dbs[combination], combination, db_dir)\n",
    "dbs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct database of counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database is a mapping from each unique n-gram that is one of our 26 types to the number of matches in all of IMSLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in iglob(f\"{db_dir}/*.pkl\", recursive=True):\n",
    "    files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.sort(key = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"/data1/kji/databases/split21_Bt_200mill.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "counts = {}\n",
    "for fp in d:\n",
    "    counts[fp] = sum([len(d[fp][piece]) for piece in d[fp]])\n",
    "d.clear()\n",
    "print(f\"finished processing {filename}\")\n",
    "store_DB(counts, f\"split21_Bt_200mill_counts\", db_dir)\n",
    "print(f\"stored database for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_DB(counts, f\"split21_Bt_200mill_counts\", db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for combination in combinations:\n",
    "    filename = f\"/data1/kji/databases2/{combination}.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = dill.load(f)\n",
    "        counts = {}\n",
    "        for fp in d:\n",
    "            counts[fp] = sum([len(d[fp][piece]) for piece in d[fp]])\n",
    "        d.clear()\n",
    "        print(f\"finished processing {filename}\")\n",
    "        f.flush()\n",
    "        store_DB(counts, f\"{combination}_counts\", db_dir)\n",
    "        print(f\"stored database for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_DB(matches, \"matches_array\", db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing /data1/kji/databases/0125_counts.pkl\n",
      "finished processing /data1/kji/databases/0134_counts.pkl\n",
      "finished processing /data1/kji/databases/0135_counts.pkl\n",
      "finished processing /data1/kji/databases/0145_counts.pkl\n",
      "finished processing /data1/kji/databases/0234_counts.pkl\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations:\n",
    "    filename = f\"/data1/kji/databases/{combination}_counts.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "        length = len(d)\n",
    "        fps = np.empty(length, dtype = object)\n",
    "        values = np.empty(length, dtype = int)\n",
    "        for i, (n_gram, count) in enumerate(d.items()):\n",
    "            fps[i] = n_gram\n",
    "            values[i] = count\n",
    "        d.clear()\n",
    "        n_grams = np.concatenate([n_grams, fps])\n",
    "        matches = np.concatenate([matches, values])\n",
    "        print(f\"finished processing {filename}\")\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make fp matches table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of PDFs that contain each fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"/data1/kji/databases_random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data1/kji/databases_v4/fp_matches.pkl\", \"rb\") as f:\n",
    "    fp_matches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_matches = {combination: {} for combination in combinations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination in combinations:\n",
    "    with open(f\"{db_dir}/{combination}.pkl\", \"rb\") as f:\n",
    "        d = dill.load(f)\n",
    "    for fp in d:\n",
    "        # first element is number of times the fingerprint occurs, second element is number of PDFs containing the fingerprint\n",
    "        fp_matches[combination][fp] = (sum(len(d[fp][piece]) for piece in d[fp]), len(d[fp]))\n",
    "    d.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/data1/kji/databases_v5/fp_matches.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fp_matches, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/data1/kji/databases_v4/fp_matches.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fp_matches, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
