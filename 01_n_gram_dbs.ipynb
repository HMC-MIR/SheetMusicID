{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases for each n-gram combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 26 different n-gram combinations with various stride lengths. This notebook constructs a database for each type of n-gram and also a database storing the counts for each n-gram type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import os\n",
    "import time\n",
    "import dill\n",
    "from tqdm import tqdm\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for n_gram in range(1, 5):\n",
    "    combinations += [[0] + list(tup) for tup in itertools.combinations(range(1, 6), n_gram-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [\"\".join(str(num) for num in combination) for combination in combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalBscore(bscore_file):\n",
    "    bscore_array = []\n",
    "    with open(bscore_file,'rb') as f:\n",
    "        bscore_array = pickle.load(f)\n",
    "    total_bscore = np.array([]).reshape(62,0)\n",
    "    for page in bscore_array:\n",
    "        try:\n",
    "            total_page = unpackbits(np.array(page), 62)\n",
    "        except TypeError:\n",
    "            total_page = np.array([]).reshape(62,0)\n",
    "            for num in page:\n",
    "                col = np.array(decodeColumn(num)).reshape(62,-1)\n",
    "                total_page = np.concatenate((total_page,col),axis=1)\n",
    "        total_bscore = np.concatenate((total_bscore,total_page),axis=1)\n",
    "    return total_bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeColumn(num):\n",
    "    col = []\n",
    "    for i in range(62):\n",
    "        col.insert(0,num%2)\n",
    "        num = int(num/2)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackbits(x, num_bits):\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "    return np.flip((x & mask).astype(bool).astype(float), 1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We precompute powers of 2 from $2^0$ to $2^{61}$ to speed up calculating hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = 1 << np.arange(62)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fps(data, combinations, dbs, piece):\n",
    "    for colindex in range(len(data)):\n",
    "        for combination in combinations:\n",
    "            cols = []\n",
    "            # we need at least enough fingerprints for all the indices in our combination\n",
    "            try:\n",
    "                for i in combination:\n",
    "                    cols.append(data[colindex+int(i)])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            fp = []\n",
    "            equals_Zero = True\n",
    "            for column in cols:\n",
    "                hashint = int(column.dot(powers))\n",
    "                fp.append(hashint)\n",
    "                if hashint != 0:\n",
    "                    equals_Zero = False\n",
    "            if equals_Zero == True:\n",
    "                continue\n",
    "            dbs[combination][tuple(fp)][piece].append(colindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DB(filelist, combinations, dbs = None):\n",
    "    if not dbs:\n",
    "        dbs = {combination: defaultdict(lambda : defaultdict(list)) for combination in combinations}\n",
    "    with open(filelist, 'r') as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            try:\n",
    "                num = curfile.split('/')[-1][0]\n",
    "                if num == 'd':\n",
    "                    data = getTotalBscore(curfile)\n",
    "                    make_fps(data.T, combinations, dbs, i)\n",
    "                else:\n",
    "                    with open(curfile, 'rb') as pickle_file:\n",
    "                        data = pickle.load(pickle_file)\n",
    "                    make_fps(data.T, combinations, dbs, i)\n",
    "            except:\n",
    "                failed.append(curfile)\n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        dill.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = 'cfg_files/db.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = '/data1/kji/databases2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(db_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a mapping from a number to each piece to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_piece = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filelist, 'r') as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            piece = curfile.split('/')[-1][:-4]\n",
    "            num_to_piece[i] = piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"num_to_piece.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(num_to_piece, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece.pkl\", 'rb') as f:\n",
    "    num_to_piece = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First loop over all combinations (total 26).\n",
    "Then loop over every single file in IMSLP.\n",
    "Then within each file, loop over every single offset and compute the n-gram given the combination.\n",
    "Increment the count for that n-gram combination in the dictionary.\n",
    "When done, pickle the dictionary and free the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 26, 2):\n",
    "    dbs = make_DB(filelist, combinations[i: i+2])\n",
    "    for combination in dbs:\n",
    "        store_DB(dbs[combination], combination, db_dir)\n",
    "    dbs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dbs = make_DB(filelist, combinations[-10:-6])\n",
    "db_end_time = time.time()\n",
    "print(f\"Finished constructing databases in {db_end_time - start} seconds\")\n",
    "for combination in dbs:\n",
    "    store_DB(dbs[combination], combination, db_dir)\n",
    "print(f\"Finished storing databases on disk in {time.time() - db_end_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct database of counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database is a mapping from each unique n-gram that is one of our 26 types to the number of matches in all of IMSLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in iglob(f\"{db_dir}/*.pkl\", recursive=True):\n",
    "    files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.sort(key = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"/data1/kji/databases/split21_Bt_200mill.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "counts = {}\n",
    "for fp in d:\n",
    "    counts[fp] = sum([len(d[fp][piece]) for piece in d[fp]])\n",
    "d.clear()\n",
    "print(f\"finished processing {filename}\")\n",
    "store_DB(counts, f\"split21_Bt_200mill_counts\", db_dir)\n",
    "print(f\"stored database for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_DB(counts, f\"split21_Bt_200mill_counts\", db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for combination in combinations:\n",
    "    filename = f\"/data1/kji/databases2/{combination}.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = dill.load(f)\n",
    "        counts = {}\n",
    "        for fp in d:\n",
    "            counts[fp] = sum([len(d[fp][piece]) for piece in d[fp]])\n",
    "        d.clear()\n",
    "        print(f\"finished processing {filename}\")\n",
    "        f.flush()\n",
    "        store_DB(counts, f\"{combination}_counts\", db_dir)\n",
    "        print(f\"stored database for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_DB(matches, \"matches_array\", db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing /data1/kji/databases/0125_counts.pkl\n",
      "finished processing /data1/kji/databases/0134_counts.pkl\n",
      "finished processing /data1/kji/databases/0135_counts.pkl\n",
      "finished processing /data1/kji/databases/0145_counts.pkl\n",
      "finished processing /data1/kji/databases/0234_counts.pkl\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations:\n",
    "    filename = f\"/data1/kji/databases/{combination}_counts.pkl\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "        length = len(d)\n",
    "        fps = np.empty(length, dtype = object)\n",
    "        values = np.empty(length, dtype = int)\n",
    "        for i, (n_gram, count) in enumerate(d.items()):\n",
    "            fps[i] = n_gram\n",
    "            values[i] = count\n",
    "        d.clear()\n",
    "        n_grams = np.concatenate([n_grams, fps])\n",
    "        matches = np.concatenate([matches, values])\n",
    "        print(f\"finished processing {filename}\")\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
